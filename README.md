## -*THIS PROGRAM IS STILL IN DEVELOPMENT & IT IS NOT FINISHED.*-
LlamaChat, a GUI local AI Chatbot using ollama
### **System Requirements** : 
*Processor*: 4-16 Core CPU depending on the model used. 

*Memory*: 8-64GB of RAM Depending on the model used. 

*Storage*: 1-200GB of SSD storage depending on the model used. 
# Installing 
If you want to use the Application, install Ollama from [*Here*](https://ollama.com/)
After you have installed Ollama, you have to install a model. For this tutorial,I will be using **Llama3.2** As it uses a moderate amount of system resources.
In your Terminal, Type in :
```
ollama pull Llama3.2
```
After you have done this, Change your directory to LlamaChat.
In your Terminal, Type in : 
```
pip3 -r install requirements.txt
```
After Running the Command, You are ready to run the application. 
To get started, Type in :
```
streamlit run /PATH/LlamaChat.py
```
**Make Sure to replace PATH with the path leading to LlamaChat.py**
And You are ready to Chat with AI, Localy.

![Screenshot 2025-01-17 203534](https://github.com/user-attachments/assets/5d30afc9-7c70-4db0-a10f-3080da5b7e8d)



